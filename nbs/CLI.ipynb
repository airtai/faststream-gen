{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6067a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff086fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from typing import *\n",
    "import os\n",
    "import re\n",
    "\n",
    "import typer\n",
    "\n",
    "from fastkafka_gen._components.logger import get_logger\n",
    "from fastkafka_gen._code_generator.app_description_validator import validate_app_description\n",
    "from fastkafka_gen._code_generator.asyncapi_spec_generator import generate_asyncapi_spec\n",
    "from fastkafka_gen._code_generator.app_generator import generate_app\n",
    "from fastkafka_gen._code_generator.test_generator import generate_test\n",
    "from fastkafka_gen._code_generator.helper import set_logger_level, add_tokens_usage\n",
    "from fastkafka_gen._code_generator.constants import DEFAULT_MODEL, MODEL_PRICING, TOKEN_TYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7308ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typer.testing import CliRunner\n",
    "import pytest\n",
    "from unittest.mock import patch\n",
    "\n",
    "from fastkafka_gen._components.logger import suppress_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d072658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da7962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "suppress_timestamps()\n",
    "logger = get_logger(__name__, level=20)\n",
    "logger.info(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1b231d",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = CliRunner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5742512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "OPENAI_KEY_EMPTY_ERROR = \"Error: OPENAI_API_KEY cannot be empty. Please set a valid OpenAI API key in OPENAI_API_KEY environment variable and try again.\\nYou can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\"\n",
    "OPENAI_KEY_NOT_SET_ERROR = \"Error: OPENAI_API_KEY not found in environment variables. Set a valid OpenAI API key in OPENAI_API_KEY environment variable and try again. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\"\n",
    "\n",
    "\n",
    "def _ensure_openai_api_key_set() -> None:\n",
    "    \"\"\"Ensure the 'OPENAI_API_KEY' environment variable is set and is not empty.\n",
    "\n",
    "    Raises:\n",
    "        KeyError: If the 'OPENAI_API_KEY' environment variable is not found.\n",
    "        ValueError: If the 'OPENAI_API_KEY' environment variable is found but its value is empty.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "        if openai_api_key == \"\":\n",
    "            raise ValueError(OPENAI_KEY_EMPTY_ERROR)\n",
    "    except KeyError:\n",
    "        raise KeyError(OPENAI_KEY_NOT_SET_ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c7f256",
   "metadata": {},
   "outputs": [],
   "source": [
    "with patch.dict(os.environ, {\"OPENAI_API_KEY\": \"\"}):\n",
    "    with pytest.raises(ValueError) as e:\n",
    "        _ensure_openai_api_key_set()\n",
    "\n",
    "print(e.value)\n",
    "assert str(e.value) == OPENAI_KEY_EMPTY_ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9a9439",
   "metadata": {},
   "outputs": [],
   "source": [
    "with patch.dict(os.environ, {}, clear=True):\n",
    "    with pytest.raises(KeyError) as e:\n",
    "        _ensure_openai_api_key_set()\n",
    "        \n",
    "print(e.value)\n",
    "assert str(e.value) == f\"'{OPENAI_KEY_NOT_SET_ERROR}'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f311f7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with patch.dict(os.environ, {\"OPENAI_API_KEY\": \"INVALID_KEY\"}):\n",
    "    _ensure_openai_api_key_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b11fc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "app = typer.Typer(\n",
    "    short_help=\"Commands for accelerating FastKafka app creation using advanced AI technology\",\n",
    "     help=\"\"\"Commands for accelerating FastKafka app creation using advanced AI technology.\n",
    "\n",
    "These commands use a combination of OpenAI's gpt-3.5-turbo and gpt-3.5-turbo-16k models to generate FastKafka code. To access this feature, kindly sign up if you haven't already and create an API key with OpenAI. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\n",
    "\n",
    "Once you have the key, please set it in the OPENAI_API_KEY environment variable before executing the code generation commands.\n",
    "\n",
    "Note: Accessing OpenAI API incurs charges. However, when you sign up for the first time, you usually get free credits that are more than enough to generate multiple FastKafka apps. For further information on pricing and free credicts, check this link: https://openai.com/pricing\n",
    "    \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f47ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _strip_white_spaces(description: str) -> str:\n",
    "    \"\"\"Remove and strip excess whitespaces from a given description\n",
    "\n",
    "    Args:\n",
    "        description: The description string to be processed.\n",
    "\n",
    "    Returns:\n",
    "        The cleaned description string.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r\"\\s+\")\n",
    "    return pattern.sub(\" \", description).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b144e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixture = \"\"\"\n",
    "    I have   a                  lot\n",
    "                of whitespaces\n",
    "                \n",
    "                \n",
    "\"\"\"\n",
    "\n",
    "expected = \"I have a lot of whitespaces\"\n",
    "actual = _strip_white_spaces(fixture)\n",
    "print(actual)\n",
    "assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01415228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _calculate_price(total_tokens_usage: Dict[str, int], model: str = DEFAULT_MODEL) -> float:\n",
    "    \"\"\"Calculates the total price based on the number of promt & completion tokens and the models price for input and output tokens (per 1k tokens).\n",
    "\n",
    "    Args:\n",
    "        total_tokens_usage: OpenAI \"usage\" dictionaries which defines prompt_tokens, completion_tokens and total_tokens\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        float: The price for used tokens\n",
    "    \"\"\"\n",
    "    model_price = MODEL_PRICING[model]\n",
    "    price = (total_tokens_usage[\"prompt_tokens\"] * model_price[\"input\"] + total_tokens_usage[\"completion_tokens\"] * model_price[\"output\"]) / 1000\n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ed23e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "usage = {\n",
    "    \"prompt_tokens\": 129,\n",
    "    \"completion_tokens\": 1,\n",
    "    \"total_tokens\": 130\n",
    "  }\n",
    "\n",
    "usage_list = [usage, usage]\n",
    "total_tokens_usage = add_tokens_usage(usage_list)\n",
    "\n",
    "assert _calculate_price(total_tokens_usage) == 0.000782"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb880142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@app.command(\n",
    "    \"generate\",\n",
    "    help=\"Effortlessly generate an AsyncAPI specification, FastKafka application code, and integration tests from the app description.\",\n",
    ")\n",
    "@set_logger_level\n",
    "def generate_fastkafka_app(\n",
    "    description: str = typer.Argument(\n",
    "        ...,\n",
    "        help=\"\"\"Summarize your FastKafka app in a few sentences!\n",
    "\n",
    "\n",
    "\\nInclude details about messages, topics, servers, and a brief overview of the intended business logic.\n",
    "\n",
    "\n",
    "\\nThe simpler and more specific the app description is, the better the generated app will be. Please refer to the below example for inspiration:\n",
    "\n",
    "\n",
    "\\nCreate a FastKafka app using localhost broker for testing, staging.example-domain.ai for staging and prod.example-domain.ai for production. Use default port number.\n",
    "\n",
    "It should consume from 'store_product' topic an JSON encoded object with the following three attributes: product_name, currency and price. The format of the currency will be three letter string, e.g. 'EUR'.\n",
    "For each consumed message, check if the currency attribute is set to 'HRK'. If it is then change the currency to 'EUR' and divide the price by 7.5, if the currency is not set to 'HRK' don't change the original message. Finally, publish the consumed message to 'change_currency' topic.\n",
    "\n",
    "Use SASL_SSL with SCRAM-SHA-256 for authentication with username and password.\n",
    "\n",
    "\n",
    "\\n\"\"\"\n",
    "    ),\n",
    "    output_path: str = typer.Option(\n",
    "        \"./fastkafka-gen\",\n",
    "        \"--output_path\",\n",
    "        \"-o\",\n",
    "        help=\"The path to the output directory where the generated files will be saved. This path should be relative to the current working directory.\",\n",
    "    ),\n",
    "    verbose: bool = typer.Option(\n",
    "        False,\n",
    "        \"--verbose\",\n",
    "        \"-v\",\n",
    "        help=\"Enable verbose logging by setting the logger level to INFO.\",\n",
    "    ),\n",
    ") -> None:\n",
    "    \"\"\"Effortlessly generate an AsyncAPI specification, FastKafka application code, and integration tests from the app description.\"\"\"\n",
    "    try:\n",
    "        _ensure_openai_api_key_set()\n",
    "        \n",
    "        cleaned_description = _strip_white_spaces(description)\n",
    "        validated_description, description_token = validate_app_description(cleaned_description)\n",
    "\n",
    "        asyncapi_spec_token = generate_asyncapi_spec(validated_description, output_path)\n",
    "        app_token = generate_app(output_path)\n",
    "        test_token = generate_test(validated_description, output_path)\n",
    "        \n",
    "        total_tokens_usage = add_tokens_usage([asyncapi_spec_token, app_token, test_token])\n",
    "        price = _calculate_price(total_tokens_usage)\n",
    "        \n",
    "        typer.secho(f\" â–¶ Total tokens usage: {total_tokens_usage['total_tokens']}\", fg=typer.colors.CYAN)\n",
    "        typer.secho(f\" ðŸ¤‘ Total price: {round(price, 5)}ðŸ’²\", fg=typer.colors.CYAN)\n",
    "        typer.secho(\"âœ¨  All files were successfully generated!\", fg=typer.colors.CYAN)\n",
    "    \n",
    "    except (ValueError, KeyError) as e:\n",
    "        typer.secho(e, err=True, fg=typer.colors.RED)\n",
    "        raise typer.Exit(code=1)\n",
    "    except Exception as e:\n",
    "        typer.secho(f\"Unexpected internal error: {e}\", err=True, fg=typer.colors.RED)\n",
    "        raise typer.Exit(code=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81371542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "\n",
    "! nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f578155",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = runner.invoke(app, [\"generate\", \"--help\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cb362c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
